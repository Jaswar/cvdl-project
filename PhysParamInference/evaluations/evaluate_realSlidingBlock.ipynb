{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation for the Real Sliding Block Experiments\n",
    "This notebook can be used to load and analyze the results generated by running `training_realSlidingBlock.py`. The path to the the folder containing `ckpt.pth` and `./hydra/` needs to be specified under `path_experiment`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T17:06:45.419133Z",
     "start_time": "2024-05-29T17:06:45.415543Z"
    }
   },
   "source": [
    "%cd .."
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jan/Documents/TUDelftMSc/CVDL/project/project/PhysParamInference\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T17:06:46.834108Z",
     "start_time": "2024-05-29T17:06:45.870602Z"
    }
   },
   "source": [
    "import os\n",
    "import yaml\n",
    "import torch\n",
    "from torchvision import utils\n",
    "from models.sceneRepresentation import Scene\n",
    "from dataset.dataset import ImageDataset_realData\n",
    "from util.util import compute_psnr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\""
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T17:06:46.836563Z",
     "start_time": "2024-05-29T17:06:46.834835Z"
    }
   },
   "source": [
    "# Set the path to the folder containing the results (/.hydra/, ckpt.pth)\n",
    "path_experiment = os.path.join(\n",
    "    os.path.abspath(''),\n",
    "    'experiments',\n",
    "    '2024-05-29',\n",
    "    'real_world',\n",
    "    'slidingBlock',\n",
    "    '18-39-05'\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T17:06:47.641139Z",
     "start_time": "2024-05-29T17:06:47.556261Z"
    }
   },
   "source": [
    "# Load the config and the checkpoint\n",
    "path_conf = os.path.join(path_experiment, '.hydra','config.yaml')\n",
    "with open(path_conf) as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "model = Scene(**cfg['scene']['background'])\n",
    "\n",
    "model.add_slidingBlock(\n",
    "    alpha=torch.tensor(0.),\n",
    "    p0=torch.ones(2),\n",
    "    **cfg['scene']['local_representation']\n",
    ")\n",
    "\n",
    "path_ckpt = os.path.join(path_experiment, 'ckpt.pth')\n",
    "model.load_state_dict(torch.load(path_ckpt))\n",
    "\n",
    "model.use_homography = cfg['homography']['enable']\n",
    "\n",
    "model.to(device)\n",
    "print(\"Moved to device\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved to device\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T17:06:47.818077Z",
     "start_time": "2024-05-29T17:06:47.670918Z"
    }
   },
   "source": [
    "# Load the data\n",
    "data_path = os.path.join(os.path.abspath(''), 'data',cfg['data']['path_data'])\n",
    "\n",
    "train_data = ImageDataset_realData(\n",
    "    **cfg['data'],\n",
    "    max_samples=cfg['data']['samples_train']\n",
    ")\n",
    "\n",
    "dataset = ImageDataset_realData(\n",
    "    **cfg['data'],\n",
    "    indices=train_data.unused_inds\n",
    ")\n",
    "\n",
    "tspan = dataset.t_steps.to(device)\n",
    "print(f\"Tspan eval data: {tspan}\")\n",
    "print(f\"Tspan train data: {train_data.t_steps}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tspan eval data: tensor([0.0000, 0.0333, 0.1000, 0.1667, 0.2333, 0.3000, 0.3667, 0.4000],\n",
      "       device='cuda:0')\n",
      "Tspan train data: tensor([0.0000, 0.0667, 0.1333, 0.2000, 0.2667, 0.3333])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jan/anaconda3/envs/physParamInference/lib/python3.8/site-packages/torch/functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3549.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T17:06:48.074778Z",
     "start_time": "2024-05-29T17:06:47.818660Z"
    }
   },
   "source": [
    "# Render images and evaluate\n",
    "model.eval()\n",
    "model.update_trafo(tspan)\n",
    "H, W = dataset.get_image_dim()\n",
    "output = model.render_image(W, H)\n",
    "ims = output[\"Image\"].cpu()\n",
    "masks = output['Mask'].cpu()\n",
    "\n",
    "psnr = compute_psnr(ims, dataset.get_full_images())\n",
    "norm = torch.norm(torch.eye(3) - model.homography_matrix.cpu())\n",
    "\n",
    "measured_alpha = 24\n",
    "rel_error_alpha = torch.abs(torch.rad2deg(model.local_representation.ode.alpha) - measured_alpha) / measured_alpha\n",
    "print(f\"PSNR: {psnr}, Norm diff: {norm}\")\n",
    "print(f\"Rel Error alpha: {100*rel_error_alpha:.2f}%\")\n",
    "print(f\"{psnr:.2f} & {norm:.2f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSNR: 27.770885467529297, Norm diff: 0.00722624221816659\n",
      "Rel Error alpha: 90.89%\n",
      "27.77 & 0.01\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T17:06:49.459467Z",
     "start_time": "2024-05-29T17:06:49.330430Z"
    }
   },
   "source": [
    "# Save the renderings to the experiments folder\n",
    "path_folder_rendering = os.path.join(path_experiment, 'renderingsRealWorld')\n",
    "os.makedirs(path_folder_rendering)\n",
    "\n",
    "# Save individual images\n",
    "for i in range(len(tspan)):\n",
    "    path = os.path.join(path_folder_rendering, f\"{i+1}_eval.jpg\")\n",
    "    cur_im = ims[i].permute(2, 0, 1)\n",
    "    utils.save_image(cur_im, path)\n",
    "\n",
    "    path = os.path.join(path_folder_rendering, f\"{i+1}_mask_eval.jpg\")\n",
    "    cur_mask = masks[i]\n",
    "    utils.save_image(cur_mask, path)\n",
    "\n",
    "    path = os.path.join(path_folder_rendering, f\"{i+1}_gt.jpg\")\n",
    "    cur_im_gt = dataset.get_full_images(i).permute(2, 0, 1)\n",
    "    utils.save_image(cur_im_gt, path)"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7f01482bfefa3a3bc7460951111586304597956327628e7e66e099af897f7956"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('nerf-pytorch3d')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5 (default, Sep  4 2020, 07:30:14) \n[GCC 7.3.0]"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
